{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "992d77fe",
   "metadata": {},
   "source": [
    "<h3>Pre-processing<h3>\n",
    "<h5>Kita hanya perlu hot one encoding untuk mengkategorikan daerah agar bisa dimengerti model<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70676221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f6f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_yogya_hp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d809eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing-location\n",
       "Ngaglik         137\n",
       "Depok            92\n",
       "Kalasan          65\n",
       "Ngemplak         57\n",
       "Gamping          54\n",
       "Sleman           51\n",
       "Mlati            50\n",
       "Godean           26\n",
       "Purwomartani     25\n",
       "CondongCatur     20\n",
       "Berbah           19\n",
       "Prambanan        13\n",
       "Sayegan          10\n",
       "Kaliurang         7\n",
       "Cebongan          5\n",
       "Moyudan           3\n",
       "Jombor            2\n",
       "Tempel            2\n",
       "Sidoarum          1\n",
       "Turi              1\n",
       "Pakem             1\n",
       "Caturtunggal      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['listing-location'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae13518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['listing-location'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7195828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>carport</th>\n",
       "      <th>surface_area</th>\n",
       "      <th>building_area</th>\n",
       "      <th>listing-location_Caturtunggal</th>\n",
       "      <th>listing-location_Cebongan</th>\n",
       "      <th>listing-location_CondongCatur</th>\n",
       "      <th>listing-location_Depok</th>\n",
       "      <th>...</th>\n",
       "      <th>listing-location_Ngaglik</th>\n",
       "      <th>listing-location_Ngemplak</th>\n",
       "      <th>listing-location_Pakem</th>\n",
       "      <th>listing-location_Prambanan</th>\n",
       "      <th>listing-location_Purwomartani</th>\n",
       "      <th>listing-location_Sayegan</th>\n",
       "      <th>listing-location_Sidoarum</th>\n",
       "      <th>listing-location_Sleman</th>\n",
       "      <th>listing-location_Tempel</th>\n",
       "      <th>listing-location_Turi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1790000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>695000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>560000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  bed  bath  carport  surface_area  building_area  \\\n",
       "0  1790000000  3.0   3.0      2.0         120.0          110.0   \n",
       "1   170000000  3.0   2.0      1.0         102.0          126.0   \n",
       "2   695000000  2.0   2.0      1.0         100.0          100.0   \n",
       "3   560000000  3.0   1.0      1.0         109.0           67.0   \n",
       "4   200000000  2.0   1.0      1.0          60.0           30.0   \n",
       "\n",
       "   listing-location_Caturtunggal  listing-location_Cebongan  \\\n",
       "0                          False                      False   \n",
       "1                          False                      False   \n",
       "2                          False                      False   \n",
       "3                          False                      False   \n",
       "4                          False                      False   \n",
       "\n",
       "   listing-location_CondongCatur  listing-location_Depok  ...  \\\n",
       "0                          False                   False  ...   \n",
       "1                          False                   False  ...   \n",
       "2                          False                   False  ...   \n",
       "3                          False                   False  ...   \n",
       "4                          False                   False  ...   \n",
       "\n",
       "   listing-location_Ngaglik  listing-location_Ngemplak  \\\n",
       "0                      True                      False   \n",
       "1                     False                      False   \n",
       "2                     False                      False   \n",
       "3                     False                      False   \n",
       "4                     False                      False   \n",
       "\n",
       "   listing-location_Pakem  listing-location_Prambanan  \\\n",
       "0                   False                       False   \n",
       "1                   False                       False   \n",
       "2                   False                       False   \n",
       "3                   False                        True   \n",
       "4                   False                       False   \n",
       "\n",
       "   listing-location_Purwomartani  listing-location_Sayegan  \\\n",
       "0                          False                     False   \n",
       "1                          False                     False   \n",
       "2                          False                     False   \n",
       "3                          False                     False   \n",
       "4                          False                     False   \n",
       "\n",
       "   listing-location_Sidoarum  listing-location_Sleman  \\\n",
       "0                      False                    False   \n",
       "1                      False                    False   \n",
       "2                      False                    False   \n",
       "3                      False                    False   \n",
       "4                      False                    False   \n",
       "\n",
       "   listing-location_Tempel  listing-location_Turi  \n",
       "0                    False                  False  \n",
       "1                    False                  False  \n",
       "2                    False                  False  \n",
       "3                    False                  False  \n",
       "4                    False                  False  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8dcbfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 642 entries, 0 to 641\n",
      "Data columns (total 27 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   price                          642 non-null    int64  \n",
      " 1   bed                            642 non-null    float64\n",
      " 2   bath                           642 non-null    float64\n",
      " 3   carport                        642 non-null    float64\n",
      " 4   surface_area                   642 non-null    float64\n",
      " 5   building_area                  642 non-null    float64\n",
      " 6   listing-location_Caturtunggal  642 non-null    bool   \n",
      " 7   listing-location_Cebongan      642 non-null    bool   \n",
      " 8   listing-location_CondongCatur  642 non-null    bool   \n",
      " 9   listing-location_Depok         642 non-null    bool   \n",
      " 10  listing-location_Gamping       642 non-null    bool   \n",
      " 11  listing-location_Godean        642 non-null    bool   \n",
      " 12  listing-location_Jombor        642 non-null    bool   \n",
      " 13  listing-location_Kalasan       642 non-null    bool   \n",
      " 14  listing-location_Kaliurang     642 non-null    bool   \n",
      " 15  listing-location_Mlati         642 non-null    bool   \n",
      " 16  listing-location_Moyudan       642 non-null    bool   \n",
      " 17  listing-location_Ngaglik       642 non-null    bool   \n",
      " 18  listing-location_Ngemplak      642 non-null    bool   \n",
      " 19  listing-location_Pakem         642 non-null    bool   \n",
      " 20  listing-location_Prambanan     642 non-null    bool   \n",
      " 21  listing-location_Purwomartani  642 non-null    bool   \n",
      " 22  listing-location_Sayegan       642 non-null    bool   \n",
      " 23  listing-location_Sidoarum      642 non-null    bool   \n",
      " 24  listing-location_Sleman        642 non-null    bool   \n",
      " 25  listing-location_Tempel        642 non-null    bool   \n",
      " 26  listing-location_Turi          642 non-null    bool   \n",
      "dtypes: bool(21), float64(5), int64(1)\n",
      "memory usage: 43.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e62109",
   "metadata": {},
   "source": [
    "Kita sudah berhasil membuat semua paramter dimengerti model, waktunya ke Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed540d2",
   "metadata": {},
   "source": [
    "<h3>Modelling<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dc54eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f328fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d1fd457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              price       bed      bath   carport  \\\n",
      "price                      1.000000  0.589641  0.710486  0.267045   \n",
      "bed                        0.589641  1.000000  0.695099  0.285481   \n",
      "bath                       0.710486  0.695099  1.000000  0.338274   \n",
      "carport                    0.267045  0.285481  0.338274  1.000000   \n",
      "surface_area               0.613885  0.507710  0.471821  0.201339   \n",
      "building_area              0.765642  0.676245  0.721186  0.208020   \n",
      "building_to_surface_ratio  0.518844  0.510974  0.561576  0.124921   \n",
      "price_per_sqm_building     0.528619  0.098980  0.201404  0.138434   \n",
      "price_per_sqm_surface      0.896696  0.481657  0.636260  0.240401   \n",
      "total_rooms                0.709955  0.909984  0.930622  0.340436   \n",
      "room_density              -0.298961 -0.142527 -0.153849 -0.043297   \n",
      "\n",
      "                           surface_area  building_area  \\\n",
      "price                          0.613885       0.765642   \n",
      "bed                            0.507710       0.676245   \n",
      "bath                           0.471821       0.721186   \n",
      "carport                        0.201339       0.208020   \n",
      "surface_area                   1.000000       0.585940   \n",
      "building_area                  0.585940       1.000000   \n",
      "building_to_surface_ratio      0.059990       0.815883   \n",
      "price_per_sqm_building         0.217994       0.007792   \n",
      "price_per_sqm_surface          0.245557       0.659479   \n",
      "total_rooms                    0.530592       0.760214   \n",
      "room_density                  -0.278554      -0.453856   \n",
      "\n",
      "                           building_to_surface_ratio  price_per_sqm_building  \\\n",
      "price                                       0.518844                0.528619   \n",
      "bed                                         0.510974                0.098980   \n",
      "bath                                        0.561576                0.201404   \n",
      "carport                                     0.124921                0.138434   \n",
      "surface_area                                0.059990                0.217994   \n",
      "building_area                               0.815883                0.007792   \n",
      "building_to_surface_ratio                   1.000000               -0.142389   \n",
      "price_per_sqm_building                     -0.142389                1.000000   \n",
      "price_per_sqm_surface                       0.654543                0.521738   \n",
      "total_rooms                                 0.584021                0.166551   \n",
      "room_density                               -0.413112                0.452650   \n",
      "\n",
      "                           price_per_sqm_surface  total_rooms  room_density  \n",
      "price                                   0.896696     0.709955     -0.298961  \n",
      "bed                                     0.481657     0.909984     -0.142527  \n",
      "bath                                    0.636260     0.930622     -0.153849  \n",
      "carport                                 0.240401     0.340436     -0.043297  \n",
      "surface_area                            0.245557     0.530592     -0.278554  \n",
      "building_area                           0.659479     0.760214     -0.453856  \n",
      "building_to_surface_ratio               0.654543     0.584021     -0.413112  \n",
      "price_per_sqm_building                  0.521738     0.166551      0.452650  \n",
      "price_per_sqm_surface                   1.000000     0.612172     -0.263980  \n",
      "total_rooms                             0.612172     1.000000     -0.161292  \n",
      "room_density                           -0.263980    -0.161292      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering  \n",
    "def create_features(df):\n",
    "    \"\"\"Create additional features that might be predictive\"\"\"\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Ratio features\n",
    "    df_new['building_to_surface_ratio'] = df_new['building_area'] / df_new['surface_area']\n",
    "    df_new['price_per_sqm_building'] = df_new['price'] / df_new['building_area']\n",
    "    df_new['price_per_sqm_surface'] = df_new['price'] / df_new['surface_area']\n",
    "    \n",
    "    # Room density features\n",
    "    df_new['total_rooms'] = df_new['bed'] + df_new['bath']\n",
    "    df_new['room_density'] = df_new['total_rooms'] / df_new['building_area']\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Prepare data\n",
    "df_features = create_features(df)\n",
    "cols_to_include = [col for col in df_features.select_dtypes(include='number').columns if not col.startswith('location_')]\n",
    "corr_matrix = df_features[cols_to_include].corr()\n",
    "print(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87de5f9",
   "metadata": {},
   "source": [
    "fitur room density tidak menunjukkan korelasi yg bagus jadi kita hapus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_features.drop('room_density', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aaddada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 642 entries, 0 to 641\n",
      "Data columns (total 31 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   price                          642 non-null    int64  \n",
      " 1   bed                            642 non-null    float64\n",
      " 2   bath                           642 non-null    float64\n",
      " 3   carport                        642 non-null    float64\n",
      " 4   surface_area                   642 non-null    float64\n",
      " 5   building_area                  642 non-null    float64\n",
      " 6   listing-location_Caturtunggal  642 non-null    bool   \n",
      " 7   listing-location_Cebongan      642 non-null    bool   \n",
      " 8   listing-location_CondongCatur  642 non-null    bool   \n",
      " 9   listing-location_Depok         642 non-null    bool   \n",
      " 10  listing-location_Gamping       642 non-null    bool   \n",
      " 11  listing-location_Godean        642 non-null    bool   \n",
      " 12  listing-location_Jombor        642 non-null    bool   \n",
      " 13  listing-location_Kalasan       642 non-null    bool   \n",
      " 14  listing-location_Kaliurang     642 non-null    bool   \n",
      " 15  listing-location_Mlati         642 non-null    bool   \n",
      " 16  listing-location_Moyudan       642 non-null    bool   \n",
      " 17  listing-location_Ngaglik       642 non-null    bool   \n",
      " 18  listing-location_Ngemplak      642 non-null    bool   \n",
      " 19  listing-location_Pakem         642 non-null    bool   \n",
      " 20  listing-location_Prambanan     642 non-null    bool   \n",
      " 21  listing-location_Purwomartani  642 non-null    bool   \n",
      " 22  listing-location_Sayegan       642 non-null    bool   \n",
      " 23  listing-location_Sidoarum      642 non-null    bool   \n",
      " 24  listing-location_Sleman        642 non-null    bool   \n",
      " 25  listing-location_Tempel        642 non-null    bool   \n",
      " 26  listing-location_Turi          642 non-null    bool   \n",
      " 27  building_to_surface_ratio      642 non-null    float64\n",
      " 28  price_per_sqm_building         642 non-null    float64\n",
      " 29  price_per_sqm_surface          642 non-null    float64\n",
      " 30  total_rooms                    642 non-null    float64\n",
      "dtypes: bool(21), float64(9), int64(1)\n",
      "memory usage: 63.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0c6275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"price\", axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135af902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: 513 samples\n",
      "Test set: 129 samples\n"
     ]
    }
   ],
   "source": [
    "# Data splitting for proper evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(f\"\\nTrain set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealEstateRegressor:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.best_model = None\n",
    "        self.best_cv_score = np.inf  # We want lowest RMSE, not highest R²\n",
    "\n",
    "    def prepare_models(self):\n",
    "        \"\"\"Define different regression models to try - with overfitting fixes\"\"\"\n",
    "        self.models = {\n",
    "            'Linear': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', LinearRegression())\n",
    "            ]),\n",
    "            'Ridge': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', Ridge(alpha=1.0))\n",
    "            ]),\n",
    "            'Lasso': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', Lasso(alpha=1000.0, max_iter=2000))\n",
    "            ]),\n",
    "            # FIX 1: Reduce polynomial degree from 2 to lower degree\n",
    "            'Polynomial_Linear_Degree1': Pipeline([\n",
    "                ('poly', PolynomialFeatures(degree=1, include_bias=False)),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', LinearRegression())\n",
    "            ]),\n",
    "            # FIX 2: Add strong regularization to polynomial features\n",
    "            'Polynomial_Ridge_Strong': Pipeline([\n",
    "                ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', Ridge(alpha=10000.0))  # Much stronger regularization\n",
    "            ]),\n",
    "            # FIX 3: Use Lasso with polynomial features to automatically select features\n",
    "            'Polynomial_Lasso': Pipeline([\n",
    "                ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', Lasso(alpha=5000.0, max_iter=3000))\n",
    "            ]),\n",
    "            # FIX 4: Use ElasticNet for balanced L1/L2 regularization\n",
    "            'Polynomial_ElasticNet': Pipeline([\n",
    "                ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', ElasticNet(alpha=1000.0, l1_ratio=0.5, max_iter=3000))\n",
    "            ]),\n",
    "            # FIX 5: Add feature selection before polynomial expansion\n",
    "            'Polynomial_SelectK': Pipeline([\n",
    "                ('selector', SelectKBest(score_func=f_regression, k=10)),  # Select top 10 features first\n",
    "                ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', Ridge(alpha=1000.0))\n",
    "            ]),\n",
    "            'RandomForest': Pipeline([\n",
    "                ('regressor', RandomForestRegressor(\n",
    "                    n_estimators=100, \n",
    "                    max_depth=10,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2,\n",
    "                    random_state=42\n",
    "                ))\n",
    "            ]),\n",
    "            'GradientBoosting': Pipeline([\n",
    "                ('regressor', GradientBoostingRegressor(\n",
    "                    n_estimators=100,\n",
    "                    max_depth=6,\n",
    "                    learning_rate=0.1,\n",
    "                    random_state=42\n",
    "                ))\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def check_data_leakage(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"Check for potential data leakage issues\"\"\"\n",
    "        print(\"=== DATA LEAKAGE CHECK ===\")\n",
    "        print(f\"Training set size: {X_train.shape}\")\n",
    "        print(f\"Test set size: {X_test.shape}\")\n",
    "        print(f\"Feature count: {X_train.shape[1]}\")\n",
    "        \n",
    "        # Check if we have more features than samples (classic overfitting scenario)\n",
    "        if X_train.shape[1] >= X_train.shape[0]:\n",
    "            print(\"⚠️  WARNING: More features than training samples - high risk of overfitting!\")\n",
    "        \n",
    "        # Check for duplicate rows between train and test\n",
    "        train_test_overlap = pd.merge(\n",
    "            pd.DataFrame(X_train), \n",
    "            pd.DataFrame(X_test), \n",
    "            how='inner'\n",
    "        ).shape[0]\n",
    "        \n",
    "        if train_test_overlap > 0:\n",
    "            print(f\"⚠️  WARNING: {train_test_overlap} overlapping rows between train and test sets!\")\n",
    "        \n",
    "        # Check target distribution\n",
    "        print(f\"Train target - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}\")\n",
    "        print(f\"Test target - Mean: {y_test.mean():.2f}, Std: {y_test.std():.2f}\")\n",
    "        \n",
    "        return train_test_overlap == 0\n",
    "\n",
    "    def evaluate_models_with_validation(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Enhanced evaluation with better overfitting detection\"\"\"\n",
    "        # First check for data issues\n",
    "        self.check_data_leakage(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        results = {}\n",
    "        cv_folds = 5\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            try:\n",
    "                print(f\"\\nEvaluating {name}...\")\n",
    "                \n",
    "                # Cross-validation\n",
    "                cv_scores = cross_val_score(model, X_train, y_train, cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "                cv_rmse_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "                # Fit model\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Training predictions\n",
    "                y_train_pred = model.predict(X_train)\n",
    "                train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "                train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "                train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "                # Test predictions\n",
    "                y_test_pred = model.predict(X_test)\n",
    "                test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "                test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "                test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "                # Calculate overfitting indicators\n",
    "                rmse_gap = train_rmse - test_rmse if test_rmse > train_rmse else 0\n",
    "                r2_gap = train_r2 - test_r2\n",
    "                cv_test_gap = cv_rmse_scores.mean() - test_rmse\n",
    "\n",
    "                results[name] = {\n",
    "                    'cv_mean_rmse': cv_rmse_scores.mean(),\n",
    "                    'cv_std_rmse': cv_rmse_scores.std(),\n",
    "                    'train_rmse': train_rmse,\n",
    "                    'train_mae': train_mae,\n",
    "                    'train_r2': train_r2,\n",
    "                    'test_rmse': test_rmse,\n",
    "                    'test_mae': test_mae,\n",
    "                    'test_r2': test_r2,\n",
    "                    'rmse_gap': rmse_gap,\n",
    "                    'r2_gap': r2_gap,\n",
    "                    'cv_test_gap': cv_test_gap,\n",
    "                    'cv_scores': cv_scores\n",
    "                }\n",
    "\n",
    "                # Enhanced reporting with overfitting detection\n",
    "                print(f\"CV RMSE = {cv_rmse_scores.mean():.0f} ± {cv_rmse_scores.std() * 2:.0f}\")\n",
    "                print(f\"Train R² = {train_r2:.4f}, Test R² = {test_r2:.4f}, Gap = {r2_gap:.4f}\")\n",
    "                \n",
    "                # Flag potential overfitting\n",
    "                if train_rmse < 100 and train_r2 > 0.999:\n",
    "                    print(\"🚨 OVERFITTING DETECTED: Perfect/near-perfect training performance\")\n",
    "                elif r2_gap > 0.1:\n",
    "                    print(f\"⚠️  Possible overfitting: R² gap = {r2_gap:.4f}\")\n",
    "                elif train_rmse == 0:\n",
    "                    print(\"🚨 SEVERE OVERFITTING: Zero training error (memorization)\")\n",
    "\n",
    "                # Model selection with overfitting protection\n",
    "                # Reject models with clear overfitting signals\n",
    "                is_overfitted = (train_r2 > 0.999) or (r2_gap > 0.02) or (train_rmse < 1000)\n",
    "                \n",
    "                if not is_overfitted:\n",
    "                    # Only consider non-overfitted models for selection\n",
    "                    if cv_rmse_scores.mean() < self.best_cv_score:\n",
    "                        self.best_cv_score = cv_rmse_scores.mean()\n",
    "                        self.best_model = name\n",
    "                else:\n",
    "                    print(f\"   ❌ {name} rejected due to overfitting\")\n",
    "                \n",
    "                # Alternative: Gap-based selection (uncomment to use instead)\n",
    "                # if not hasattr(self, 'best_gap'):\n",
    "                #     self.best_gap = np.inf\n",
    "                # if r2_gap < self.best_gap and test_r2 > 0.85:  # Only consider models with good performance\n",
    "                #     self.best_gap = r2_gap\n",
    "                #     self.best_model = name\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {name}: {e}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def feature_importance(self, X):\n",
    "        \"\"\"Get feature importance if available\"\"\"\n",
    "        model = self.fitted_model\n",
    "\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            # For tree-based models (RandomForest, GradientBoosting)\n",
    "            importance = model.feature_importances_\n",
    "            features = X.columns\n",
    "\n",
    "        elif hasattr(model, 'named_steps'):\n",
    "            # For linear models inside pipelines\n",
    "            regressor = model.named_steps['regressor']\n",
    "\n",
    "            if hasattr(regressor, 'coef_'):\n",
    "                importance = np.abs(regressor.coef_)\n",
    "\n",
    "                # Handle PolynomialFeatures if used\n",
    "                if 'poly' in model.named_steps:\n",
    "                    poly = model.named_steps['poly']\n",
    "                    features = poly.get_feature_names_out(X.columns)\n",
    "                else:\n",
    "                    features = X.columns\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        # Make sure lengths match\n",
    "        if len(features) != len(importance):\n",
    "            print(\"Length mismatch: Cannot generate feature importance.\")\n",
    "            return None\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    def fit_best_model(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Fit the best performing model and show detailed results\"\"\"\n",
    "        if self.best_model:\n",
    "            print(f\"\\nFitting best model: {self.best_model}\")\n",
    "            self.fitted_model = self.models[self.best_model]\n",
    "            self.fitted_model.fit(X_train, y_train)\n",
    "\n",
    "            y_train_pred = self.fitted_model.predict(X_train)\n",
    "            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "            train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "            y_test_pred = self.fitted_model.predict(X_test)\n",
    "            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "            test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "            print(f\"Training Performance:\")\n",
    "            print(f\"RMSE: {train_rmse:,.0f}, MAE: {train_mae:,.0f}, R²: {train_r2:.4f}\")\n",
    "            print(f\"Test Performance:\")\n",
    "            print(f\"RMSE: {test_rmse:,.0f}, MAE: {test_mae:,.0f}, R²: {test_r2:.4f}\")\n",
    "\n",
    "            return y_test_pred\n",
    "        else:\n",
    "            print(\"No model was selected as best. Please run evaluate_models first.\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b741132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Evaluation ===\n",
      "=== DATA LEAKAGE CHECK ===\n",
      "Training set size: (513, 30)\n",
      "Test set size: (129, 30)\n",
      "Feature count: 30\n",
      "Train target - Mean: 1115962962.96, Std: 674433582.22\n",
      "Test target - Mean: 1057155038.74, Std: 651613171.86\n",
      "\n",
      "Evaluating Linear...\n",
      "CV RMSE = 105508619 ± 24111998\n",
      "Train R² = 0.9787, Test R² = 0.9700, Gap = 0.0087\n",
      "\n",
      "Evaluating Ridge...\n",
      "CV RMSE = 105344133 ± 24289911\n",
      "Train R² = 0.9786, Test R² = 0.9662, Gap = 0.0124\n",
      "\n",
      "Evaluating Lasso...\n",
      "CV RMSE = 105507381 ± 24113201\n",
      "Train R² = 0.9787, Test R² = 0.9700, Gap = 0.0087\n",
      "\n",
      "Evaluating Polynomial_Linear_Degree1...\n",
      "CV RMSE = 105508619 ± 24111998\n",
      "Train R² = 0.9787, Test R² = 0.9700, Gap = 0.0087\n",
      "\n",
      "Evaluating Polynomial_Ridge_Strong...\n",
      "CV RMSE = 354801380 ± 60265820\n",
      "Train R² = 0.7692, Test R² = 0.7174, Gap = 0.0518\n",
      "   ❌ Polynomial_Ridge_Strong rejected due to overfitting\n",
      "\n",
      "Evaluating Polynomial_Lasso...\n",
      "CV RMSE = 23403195 ± 33199577\n",
      "Train R² = 1.0000, Test R² = 0.9697, Gap = 0.0302\n",
      "   ❌ Polynomial_Lasso rejected due to overfitting\n",
      "\n",
      "Evaluating Polynomial_ElasticNet...\n",
      "CV RMSE = 636911520 ± 60819474\n",
      "Train R² = 0.1093, Test R² = 0.0936, Gap = 0.0157\n",
      "\n",
      "Evaluating Polynomial_SelectK...\n",
      "CV RMSE = 142695206 ± 36941618\n",
      "Train R² = 0.9642, Test R² = 0.8825, Gap = 0.0817\n",
      "   ❌ Polynomial_SelectK rejected due to overfitting\n",
      "\n",
      "Evaluating RandomForest...\n",
      "CV RMSE = 89720768 ± 38837298\n",
      "Train R² = 0.9961, Test R² = 0.9880, Gap = 0.0082\n",
      "\n",
      "Evaluating GradientBoosting...\n",
      "CV RMSE = 82780776 ± 35952419\n",
      "Train R² = 1.0000, Test R² = 0.9921, Gap = 0.0079\n",
      "   ❌ GradientBoosting rejected due to overfitting\n",
      "\n",
      "=== Best Model Training ===\n",
      "\n",
      "Fitting best model: RandomForest\n",
      "Training Performance:\n",
      "RMSE: 42,038,503, MAE: 19,926,803, R²: 0.9961\n",
      "Test Performance:\n",
      "RMSE: 71,248,166, MAE: 37,899,746, R²: 0.9880\n",
      "\n",
      "====================================================================================================\n",
      "COMPREHENSIVE REGRESSION RESULTS SUMMARY\n",
      "====================================================================================================\n",
      "TABLE 1: Model Performance Comparison\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                    Model CV_Mean_RMSE CV_Std_RMSE Train_RMSE Train_MAE Train_R² Test_RMSE  Test_MAE Test_R²\n",
      "         GradientBoosting     82780776    17976209    2362617   1725927   1.0000  57764508  29009155  0.9921\n",
      "             RandomForest     89720768    19418649   42038503  19926803   0.9961  71248166  37899746  0.9880\n",
      "                    Lasso    105507381    12056601   98389788  69736097   0.9787 112390118  67053865  0.9700\n",
      "                   Linear    105508619    12055999   98389786  69735390   0.9787 112393125  67056032  0.9700\n",
      "Polynomial_Linear_Degree1    105508619    12055999   98389786  69735390   0.9787 112393125  67056032  0.9700\n",
      "         Polynomial_Lasso     23403195    16599789    2742437   1800517   1.0000 112902092  13310915  0.9697\n",
      "                    Ridge    105344133    12144956   98512360  70198545   0.9786 119264914  68423425  0.9662\n",
      "       Polynomial_SelectK    142695206    18470809  127397956  90914607   0.9642 222477500 108201895  0.8825\n",
      "  Polynomial_Ridge_Strong    354801380    30132910  323667434 255623652   0.7692 345041257 261287857  0.7174\n",
      "    Polynomial_ElasticNet    636911520    30409737  635894371 533381898   0.1093 617957909 515036578  0.0936\n"
     ]
    }
   ],
   "source": [
    "# Initialize and run the regressor\n",
    "regressor = RealEstateRegressor()\n",
    "regressor.prepare_models()\n",
    "\n",
    "print(\"=== Model Evaluation ===\")\n",
    "results = regressor.evaluate_models_with_validation(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(f\"\\n=== Best Model Training ===\")\n",
    "y_test_pred = regressor.fit_best_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Comprehensive Results Summary\n",
    "print(f\"\\n\" + \"=\"*100)\n",
    "print(f\"COMPREHENSIVE REGRESSION RESULTS SUMMARY\")\n",
    "print(f\"=\"*100)\n",
    "\n",
    "# Create results DataFrame for paper\n",
    "results_df = pd.DataFrame()\n",
    "for model_name, metrics in results.items():\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\n",
    "        'Model': [model_name],\n",
    "        'CV_Mean_RMSE': [f\"{metrics['cv_mean_rmse']:.0f}\"],\n",
    "        'CV_Std_RMSE': [f\"{metrics['cv_std_rmse']:.0f}\"],\n",
    "        'Train_RMSE': [f\"{metrics['train_rmse']:.0f}\"],\n",
    "        'Train_MAE': [f\"{metrics['train_mae']:.0f}\"],\n",
    "        'Train_R²': [f\"{metrics['train_r2']:.4f}\"],\n",
    "        'Test_RMSE': [f\"{metrics['test_rmse']:.0f}\"],\n",
    "        'Test_MAE': [f\"{metrics['test_mae']:.0f}\"],\n",
    "        'Test_R²': [f\"{metrics['test_r2']:.4f}\"]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "# Sort by test R² performance (higher is better)\n",
    "results_df['Test_R²_numeric'] = [float(x) for x in results_df['Test_R²']]\n",
    "results_df = results_df.sort_values('Test_R²_numeric', ascending=False).drop('Test_R²_numeric', axis=1)\n",
    "\n",
    "print(\"TABLE 1: Model Performance Comparison\")\n",
    "print(\"-\" * 100)\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1aaa7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"data/perbandingan_hasil.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "house_pricing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
